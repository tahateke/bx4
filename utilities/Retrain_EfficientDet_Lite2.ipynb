{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "license"
      },
      "source": [
        "##### *Copyright 2021 Google LLC*\n",
        "*Licensed under the Apache License, Version 2.0 (the \"License\")*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "rKwqeqWBXANA"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Retrain EfficientDet-Lite2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3q-gvm3cI8"
      },
      "source": [
        "In this tutorial, we'll retrain the EfficientDet-Lite2 object detection model (derived from [EfficientDet](https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html)) using the [TensorFlow Lite Model Maker library](https://www.tensorflow.org/lite/guide/model_maker), and then compile it to run on the [Coral Edge TPU](https://www.coral.ai/products/).\n",
        "\n",
        "We'll retrain the model using your custom dataset in the TFRecord format.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q71Xw88S-kU6"
      },
      "source": [
        "##Compute resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYVJ1mNt-kAP"
      },
      "source": [
        "Run the following code to make sure you're using a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmKV44-J-jyk"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMXyeUfl-ipw"
      },
      "source": [
        "If you have Colab Pro you have the option to access high-memory VMs when they are available. To set your notebook preference to use a high-memory runtime, select the Runtime > 'Change runtime type' menu, and then select High-RAM in the Runtime shape dropdown.\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9U8WEtt-iYG"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vvAObmTqglq"
      },
      "source": [
        "## Import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhl8lqVamEty"
      },
      "outputs": [],
      "source": [
        "!pip install -q tflite-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0XM-oIfhgQ7"
      },
      "source": [
        "## Load the training data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-yxSd8jBR3O"
      },
      "source": [
        "Create directory to store datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwsylZdXBRCE"
      },
      "outputs": [],
      "source": [
        "%mkdir ~/content\n",
        "%mkdir ~/content/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRd13bfetO7B"
      },
      "source": [
        "Label your images and convert your datasets to the TFRecord format as `rocket_train.tfrecord` and `rocket_validation.tfrecord`. Then, save `rocket_train.tfrecord` and `rocket_validation.tfrecord` to the dataset directory `~/content/dataset`.\n",
        "\n",
        "Model Maker requires that we load our dataset using the [`DataLoader`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/DataLoader) API.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otKMgu87CXmQ"
      },
      "outputs": [],
      "source": [
        "! test ! -f ~/content/dataset/rocket_train.tfrecord && echo \"~/content/dataset/rocket_train.tfrecord not found\"\n",
        "! test ! -f ~/content/dataset/rocket_validation.tfrecord && echo \"~/content/dataset/rocket_validation.tfrecord not found\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_fP--GwCaH8"
      },
      "source": [
        "Model Maker requires that we load our dataset using the DataLoader API, which supports the TFRecord format. Load the training and validation data from their locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04ObtdneqvP5"
      },
      "outputs": [],
      "source": [
        "label_map = {1: 'Rocket'}\n",
        "train_size = 791\n",
        "validation_size = 170\n",
        "\n",
        "train_data = object_detector.DataLoader(tfrecord_file_patten=os.path.expanduser('~/content/dataset/rocket_train.tfrecord'), size=train_size, label_map=label_map)\n",
        "validation_data = object_detector.DataLoader(tfrecord_file_patten=os.path.expanduser('~/content/dataset/rocket_validation.tfrecord'), size=validation_size, label_map=label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMcWSQF_38Y-"
      },
      "source": [
        "## Launch Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaUfjn4pHAaZ"
      },
      "source": [
        "Enable Tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hKH_5SXG_lI"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKO-ZMFV4A4n"
      },
      "source": [
        "Create the directory to save the TFLite model checkpoint information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLFFnaL1377e"
      },
      "outputs": [],
      "source": [
        "%mkdir ~/content/checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TtTnHFw4KQO"
      },
      "source": [
        "TensorBoard is optional but provides very helpful visualizations of your training progress and accuracy evaluations.\n",
        "\n",
        "Because TensorBoard runs as a webserver on your local machine—and we're actually running this on a Colab virtual environment—we'll use a tool called ngrok to make this server accessible with a public URL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnfljVW-4Oq0"
      },
      "outputs": [],
      "source": [
        "%cd ~/content\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip -o ngrok-stable-linux-amd64.zip\n",
        "! ./ngrok authtoken 1uHLb8EGigeEdiOZhydEmGphJ4h_7VuPxKSZjfmb6Bth3g2Cx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRdzFPKV4X3P"
      },
      "outputs": [],
      "source": [
        "# Starts tensorboard, so we can monitor the training process.\n",
        "get_ipython().magic(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006'\n",
        "    .format(os.path.expanduser('~/content/checkpoints'))\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "print('Click this link to view training progress in TensorBoard:')\n",
        "import time\n",
        "time.sleep(1)\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "print('Don\\'t worry about the error page below, Tensorboard is running in the background')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8clx0KPutCM"
      },
      "source": [
        "## Create and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn61LJ9QbOPi"
      },
      "source": [
        "Model Maker supports the EfficientDet-Lite family of object detection models that are compatible with the Edge TPU. (EfficientDet-Lite is derived from [EfficientDet](https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html), which offers state-of-the-art accuracy in a small model size). There are several model sizes you can choose from:\n",
        "\n",
        "|| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n",
        "|-|--------------------|-----------|---------------|----------------------|\n",
        "|| EfficientDet-Lite0 | 4.4       | 37            | 25.69%               |\n",
        "|| EfficientDet-Lite1 | 5.8       | 49            | 30.55%               |\n",
        "|| EfficientDet-Lite2 | 7.2       | 69            | 33.97%               |\n",
        "|| EfficientDet-Lite3 | 11.4      | 116           | 37.70%               |\n",
        "|| EfficientDet-Lite4 | 19.9      | 260           | 41.96%               |\n",
        "| <td colspan=4><br><i>* File size of the integer quantized models. <br/>** Latency measured on Pixel 4 using 4 threads on CPU. <br/>*** Average Precision is the mAP (mean Average Precision) on the COCO 2017 validation dataset.</i></td> |\n",
        "\n",
        "Beware that the bigger models (Lite3 and Lite4) do not fit onto the Edge TPU's onboard memory, so you'll see even greater latency when using those due to the cost of fetching data from the host system memory. Maybe this extra latency is okay for your application, but if it's not and you require the precision of the larger models, then you can [pipeline the model across multiple Edge TPUs](https://coral.ai/docs/edgetpu/pipeline/) (more about this when we compile the model below).\n",
        "\n",
        "For this tutorial, we'll use Lite0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM9gePHw9Jv1"
      },
      "outputs": [],
      "source": [
        "spec = object_detector.EfficientDetLite2Spec(model_dir=os.path.expanduser('~/content/checkpoints'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnCzdzs0-Rbo"
      },
      "source": [
        "The [`EfficientDetLite2Spec`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/EfficientDetLite2Spec) constructor also supports several arguments that specify training options, such as the max number of detections (default is 25 for the TF Lite model). You can also use the constructor to specify the number of training epochs and the batch size, but you can also specify those in the next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39jLxp_VWzzG"
      },
      "source": [
        "Run the jollowing JS code in the browser console to stop Colab from disconnecting:\n",
        "\n",
        "```\n",
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "}\n",
        "setInterval(ConnectButton,60000);\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uZkLR6N6gDR"
      },
      "source": [
        "Now we need to create our model according to the model spec, load our dataset into the model, specify training parameters, and begin training. \n",
        "\n",
        "Using Model Maker, we accomplished all of that with [`create()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/create):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwlYdTcg63xy"
      },
      "outputs": [],
      "source": [
        "epochs = 300\n",
        "batch_size = 32\n",
        "\n",
        "model = object_detector.create(train_data=train_data, \n",
        "                               model_spec=spec, \n",
        "                               validation_data=validation_data, \n",
        "                               epochs=epochs, \n",
        "                               batch_size=batch_size, \n",
        "                               train_whole_model=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw-lEW2JZAEV"
      },
      "source": [
        "## Choose the best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wl-dLqZZGsB"
      },
      "source": [
        "Analyze the performance metrics at the Tensorboard and choose the best performing checkpoint that isn't overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6XtcrBaJ0my"
      },
      "outputs": [],
      "source": [
        "best_checkpoint = 125\n",
        "best_model = object_detector.create(train_data=train_data, \n",
        "                               model_spec=spec, \n",
        "                               validation_data=validation_data, \n",
        "                               epochs=epochs, \n",
        "                               batch_size=batch_size, \n",
        "                               train_whole_model=True,\n",
        "                               do_train=False)\n",
        "best_model.model.load_weights(os.path.expanduser('~/content/checkpoints/ckpt-' + best_checkpoint))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n5-o3vvGfnJ"
      },
      "source": [
        "## Evaluate the best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BzCHLWJ6h7q"
      },
      "source": [
        "Now we'll use the remaining 25 images in our test dataset to evaluate how well the model performs with data it has never seen before.\n",
        "\n",
        "The [`evaluate()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/ObjectDetector#evaluate) method provides output in the style of [COCO evaluation metrics](https://cocodataset.org/#detection-eval):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xmnl6Yy7ARn"
      },
      "outputs": [],
      "source": [
        "best_model.evaluate(data=validation_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEon9xd2BDS_"
      },
      "source": [
        "Set `batch_size` to 32. Otherwise, there can be an out of memory error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yB_XMpqGlLs"
      },
      "source": [
        "## Export to TensorFlow Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCDMe0e6jlT"
      },
      "source": [
        "Next, we'll export the model to the TensorFlow Lite format. By default, the [`export()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/ObjectDetector#export) method performs [full integer post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization), which is exactly what we need for compatibility with the Edge TPU. (Model Maker uses the same dataset we gave to our model spec as a representative dataset, which is required for full-int quantization.)\n",
        "\n",
        "We just need to specify the export directory and format. By default, it exports to TF Lite, but we also want a labels file, so we declare both:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKd6qk7TbxYO"
      },
      "outputs": [],
      "source": [
        "%mkdir ~/content/models\n",
        "best_model.export(export_dir=os.path.expanduser('~/content/models'),\n",
        "                  tflite_filename='efficientdet-lite2-rocket-quant.tflite',\n",
        "                  label_filename='rocket-labels.txt',\n",
        "                  export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b94hZ-exOCRB"
      },
      "source": [
        "### Evaluate the TF Lite model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQpahAIBqBPp"
      },
      "source": [
        "Exporting the model to TensorFlow Lite can affect the model accuracy, due to the reduced numerical precision from quantization and because the original TensorFlow model uses per-class [non-max supression (NMS)](https://www.coursera.org/lecture/convolutional-neural-networks/non-max-suppression-dvrjH) for post-processing, while the TF Lite model uses global NMS, which is faster but less accurate.\n",
        "\n",
        "Therefore you should always evaluate the exported TF Lite model and be sure it still meets your requirements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS3Ell_lqH4e"
      },
      "outputs": [],
      "source": [
        "model.evaluate_tflite(os.path.expanduser('~/content/models/efficientdet-lite2-rocket-quant.tflite'), validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph88z7PdOeX7"
      },
      "source": [
        "### Test it on a new image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me6_RwPZqNhX"
      },
      "source": [
        "Just to be sure of things, let's run an inference with the TF Lite model ourselves. \n",
        "\n",
        "To simplify our code, we'll use the [PyCoral API](https://coral.ai/docs/reference/py/):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmgtGBqua1N3"
      },
      "outputs": [],
      "source": [
        "! python3 -m pip install --extra-index-url https://google-coral.github.io/py-repo/ pycoral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkXtipXKqXp4"
      },
      "outputs": [],
      "source": [
        "# Set the model files\n",
        "MODEL_FILE = os.path.expanduser('~/content/models/efficientdet-lite2-rocket-quant.tflite')\n",
        "LABELS_FILE = os.path.expanduser('~/content/models/rocket-labels.txt')\n",
        "DETECTION_THRESHOLD = 0.2\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "\n",
        "import tflite_runtime.interpreter as tflite \n",
        "from pycoral.adapters import common\n",
        "from pycoral.adapters import detect\n",
        "from pycoral.utils.dataset import read_label_file\n",
        "\n",
        "def draw_objects(draw, objs, labels):\n",
        "  \"\"\"Draws the bounding box and label for each object.\"\"\"\n",
        "  COLORS = np.random.randint(0, 255, size=(len(labels), 3), dtype=np.uint8)\n",
        "  for obj in objs:\n",
        "    bbox = obj.bbox\n",
        "    color = tuple(int(c) for c in COLORS[obj.id])\n",
        "    draw.rectangle([(bbox.xmin, bbox.ymin), (bbox.xmax, bbox.ymax)],\n",
        "                   outline=color, width=15)\n",
        "    font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", size=90)\n",
        "    draw.text((bbox.xmin + 20, bbox.ymin + 20),\n",
        "              '%s\\n%.2f' % (labels.get(obj.id, obj.id), obj.score),\n",
        "              fill=color, font=font)\n",
        "\n",
        "# Load the TF Lite model\n",
        "labels = read_label_file(LABELS_FILE)\n",
        "interpreter = tflite.Interpreter(MODEL_FILE)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "#   # Resize the image\n",
        "image = Image.open(os.path.expanduser('~/content/models/rocket0.jpg'))\n",
        "_, scale = common.set_resized_input(\n",
        "    interpreter, image.size, lambda size: image.resize(size, Image.ANTIALIAS))\n",
        "\n",
        "# Run inference and draw boxes\n",
        "interpreter.invoke()\n",
        "objs = detect.get_objects(interpreter, DETECTION_THRESHOLD, scale)\n",
        "draw_objects(ImageDraw.Draw(image), objs, labels)\n",
        "\n",
        "# Show the results\n",
        "width = 400\n",
        "height_ratio = image.height / image.width\n",
        "image.resize((width, int(width * height_ratio)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxgWQyYOqZha"
      },
      "source": [
        "## Compile for the Edge TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0QLiwCj9Pw6"
      },
      "source": [
        "First we need to download the Edge TPU Compiler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy3QIn_YqaRP"
      },
      "outputs": [],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWewhqFqeL_"
      },
      "source": [
        "Before compiling the `.tflite` file for the Edge TPU, it's important to consider whether your model will fit into the Edge TPU memory. \n",
        "\n",
        "The Edge TPU has approximately 8 MB of SRAM for [caching model paramaters](https://coral.ai/docs/edgetpu/compiler/#parameter-data-caching), so any model close to or over 8 MB will not fit onto the Edge TPU memory. That means the inference times are longer, because some model parameters must be fetched from the host system memory.\n",
        "\n",
        "One way to elimiate the extra latency is to use [model pipelining](https://coral.ai/docs/edgetpu/pipeline/), which splits the model into segments that can run on separate Edge TPUs in series. This can significantly reduce the latency for big models.\n",
        "\n",
        "The following table provides recommendations for the number of Edge TPUs to use with each EfficientDet-Lite model.\n",
        "\n",
        "| Model architecture | Minimum TPUs | Recommended TPUs\n",
        "|--------------------|-------|-------|\n",
        "| EfficientDet-Lite0 | 1     | 1     |\n",
        "| EfficientDet-Lite1 | 1     | 1     |\n",
        "| EfficientDet-Lite2 | 1     | 2     |\n",
        "| EfficientDet-Lite3 | 2     | 2     |\n",
        "| EfficientDet-Lite4 | 2     | 3     |\n",
        "\n",
        "If you need extra Edge TPUs for your model, then update `NUMBER_OF_TPUS` here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZdonJGCqieU"
      },
      "outputs": [],
      "source": [
        "NUMBER_OF_TPUS =  1\n",
        "\n",
        "!edgetpu_compiler efficientdet-lite2-rocket-quant_edgetpu.tflite --num_segments=$NUMBER_OF_TPUS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2CjkduY02DF"
      },
      "source": [
        "**Beware when using multiple segments:** The Edge TPU Comiler divides the model such that all segments have roughly equal amounts of parameter data, but that does not mean all segments have the same latency. Especially when dividing an SSD model such as EfficientDet, this results in a latency-imbalance between segments, because SSD models have a large post-processing op that actually executes on the CPU, not on the Edge TPU. So although segmenting your model this way is better than running the whole model on just one Edge TPU, we recommend that you segment the EfficientDet-Lite model using our [profiling-based partitioner tool](https://github.com/google-coral/libcoral/tree/master/coral/tools/partitioner#profiling-based-partitioner-for-the-edge-tpu-compiler), which measures each segment's latency on the Edge TPU and then iteratively adjusts the segmentation sizes to provide balanced latency between all segments."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "license"
      ],
      "machine_shape": "hm",
      "name": "Retrain_EfficientDet_Lite2.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}